{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning de LLM com o Dataset AmazonTitles-1.3MM\n",
    "\n",
    "Este notebook demonstra o processo de fine-tuning de um modelo BERT usando o dataset AmazonTitles-1.3MM. O objetivo é treinar o modelo para gerar respostas baseadas em títulos e descrições de produtos da Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Instalação das Dependências\n",
    "\n",
    "Primeiro, vamos instalar as bibliotecas necessárias para o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação das Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonTitlesDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            item['title'],\n",
    "            item['content'],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        }\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuração do Modelo e Tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparação dos Dados para Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o Google Colab, você pode fazer upload do arquivo ou usar um link para download\n",
    "# Exemplo de upload:\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Após o upload, use o nome do arquivo carregado\n",
    "file_name = list(uploaded.keys())[0]\n",
    "data = load_data(file_name)\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.1)\n",
    "\n",
    "train_dataset = AmazonTitlesDataset(train_data, tokenizer, max_length=128)\n",
    "val_dataset = AmazonTitlesDataset(val_data, tokenizer, max_length=128)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configuração do Otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loop de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validação\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            val_loss += outputs.loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss/len(val_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Salvando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('fine_tuned_model')\n",
    "tokenizer.save_pretrained('fine_tuned_model')\n",
    "\n",
    "# Para baixar o modelo treinado do Colab\n",
    "from google.colab import files\n",
    "files.download('fine_tuned_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Função para Gerar Respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(title, content):\n",
    "    inputs = tokenizer.encode_plus(title, content, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Aqui você pode mapear a classe prevista para uma resposta apropriada\n",
    "    responses = [\"Resposta negativa\", \"Resposta neutra\", \"Resposta positiva\"]\n",
    "    return responses[predicted_class]\n",
    "\n",
    "# Exemplo de uso\n",
    "title = \"Smartphone de última geração\"\n",
    "content = \"Este smartphone possui câmera de alta resolução, bateria de longa duração e processador potente.\"\n",
    "response = generate_response(title, content)\n",
    "print(f\"Pergunta: {title}\")\n",
    "print(f\"Resposta gerada: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Este notebook demonstra o processo de fine-tuning de um modelo BERT usando o dataset AmazonTitles-1.3MM. O modelo treinado pode ser usado para gerar respostas baseadas em títulos e descrições de produtos.\n",
    "\n",
    "Lembre-se de que este é um exemplo simplificado e pode ser aprimorado de várias maneiras:\n",
    "\n",
    "1. Ajuste de hiperparâmetros para melhorar o desempenho.\n",
    "2. Implementação de técnicas de regularização para evitar overfitting.\n",
    "3. Uso de GPU para acelerar o treinamento (já habilitado no Colab).\n",
    "4. Implementação de early stopping.\n",
    "5. Utilização de técnicas mais avançadas de NLP para geração de respostas.\n",
    "\n",
    "Para um projeto real, considere também implementar uma avaliação mais robusta do modelo e adaptar o código conforme necessário para atender aos requisitos específicos do projeto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

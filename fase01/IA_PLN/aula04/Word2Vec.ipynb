{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rivervaladao/FIAP-POS-TECH/blob/master/IA_PLN/aula04/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "uCwbf8HSyzb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/Word2Vec/cbow_s300.zip\""
      ],
      "metadata": {
        "id": "i2WsTpvmQDBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format('cbow_s300.txt')\n"
      ],
      "metadata": {
        "id": "srSKSci0yV30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nuhb7vweiES1",
        "outputId": "2f334cac-ed60-43c2-93bb-0dc051287f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ba1c05ba7557>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract words and their corresponding vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m  \u001b[0;31m# List of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# Extract words and their corresponding vectors\n",
        "words = model.index_to_key  # List of words\n",
        "vectors = [model[word] for word in words]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(vectors, index=words)\n"
      ],
      "metadata": {
        "id": "sBULV_UkjK_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "ijpRSvrhjNQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_vector(\"china\")"
      ],
      "metadata": {
        "id": "vfBWnN6y2vOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(\"china\")"
      ],
      "metadata": {
        "id": "Aj05nZvN3QdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=[\"brasil\", \"uruguai\"])"
      ],
      "metadata": {
        "id": "Za_7DJLD6zee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#carro -> carros : foguete -> foguetes\n",
        "#carros + foguete - carro = foguetes\n",
        "\n",
        "model.most_similar(positive=[\"carros\", \"foguete\"], negative=[\"carro\"])"
      ],
      "metadata": {
        "id": "6apkpRMV770p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vetorização**"
      ],
      "metadata": {
        "id": "Ju4RoizC820x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artigo_treino.title[12]"
      ],
      "metadata": {
        "id": "Hw_vrYKs84YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "\n",
        "def tokenizador(texto):\n",
        "  texto = texto.lower()\n",
        "  lista_alfanumerico = []\n",
        "\n",
        "  for token_valido in nltk.word_tokenize(texto):\n",
        "    if token_valido in string.punctuation: continue\n",
        "    lista_alfanumerico.append(token_valido)\n",
        "\n",
        "  return lista_alfanumerico"
      ],
      "metadata": {
        "id": "afw2da298-Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizador(\"Texto com, pontuação.\")"
      ],
      "metadata": {
        "id": "WubjEdlR96S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def combinacao_de_vetores_por_soma(palavras_numeros):\n",
        "  vetor_resultante = np.zeros(300)\n",
        "  for pn in palavras_numeros:\n",
        "    try:\n",
        "      vetor_resultante =+ modelo.get_vector(pn)\n",
        "    except KeyError:\n",
        "      if pn.isnumeric():\n",
        "        pn = \"0\"*len(pn)\n",
        "        vetor_resultante =+ modelo.get_vector(pn)\n",
        "      else:\n",
        "        vetor_resultante =+ modelo.get_vector('unknown')\n",
        "  return vetor_resultante"
      ],
      "metadata": {
        "id": "Tc453BR0-4Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavras_numeros = tokenizador(\"texto fiaps\")\n",
        "vetor_texto = combinacao_de_vetores_por_soma(palavras_numeros)\n",
        "print(len(vetor_texto))\n",
        "print(vetor_texto)"
      ],
      "metadata": {
        "id": "DHJJ2GFj_aDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matriz_vetores(textos):\n",
        "  x = len(textos)\n",
        "  y = 300\n",
        "  matriz = np.zeros((x,y))\n",
        "\n",
        "  for i in range(x):\n",
        "    palavras_numeros = tokenizador(textos.iloc[i])\n",
        "    matriz[i] = combinacao_de_vetores_por_soma(palavras_numeros)\n",
        "\n",
        "  return matriz"
      ],
      "metadata": {
        "id": "DliReRW4_jfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_vetores_treino = matriz_vetores(artigo_treino.title)\n",
        "matriz_vetores_teste = matriz_vetores(artigo_teste.title)\n",
        "print(matriz_vetores_treino.shape)\n",
        "print(matriz_vetores_teste.shape)"
      ],
      "metadata": {
        "id": "phqPsSeeDpyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression(max_iter = 200)\n",
        "LR.fit(matriz_vetores_treino, artigo_treino.category)"
      ],
      "metadata": {
        "id": "KSVRrr9zEZZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR.score(matriz_vetores_teste, artigo_teste.category)"
      ],
      "metadata": {
        "id": "SMIU0c-uFYUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artigo_teste.category.unique()"
      ],
      "metadata": {
        "id": "y4fqzV4KGcE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "label_prevista = LR.predict(matriz_vetores_teste)\n",
        "CR = classification_report(artigo_teste.category, label_prevista)\n",
        "print(CR)"
      ],
      "metadata": {
        "id": "cn-ET1r0GtNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "DC = DummyClassifier()\n",
        "DC.fit(matriz_vetores_treino, artigo_treino.category)\n",
        "label_previsao_dc = DC.predict(matriz_vetores_teste)\n",
        "CR_dummy = classification_report(artigo_teste.category, label_previsao_dc)\n",
        "print(CR_dummy)"
      ],
      "metadata": {
        "id": "w25KWnS5HV3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/Word2Vec/skip_s300.zip\""
      ],
      "metadata": {
        "id": "14xbDCPqNWft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_skipgram = KeyedVectors.load_word2vec_format(\"skip_s300.txt\")"
      ],
      "metadata": {
        "id": "JNjMPw6MMlXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combinacao_de_vetores_por_soma_skipgram(palavras_numeros):\n",
        "  vetor_resultante = np.zeros(300)\n",
        "  for pn in palavras_numeros:\n",
        "    try:\n",
        "      vetor_resultante =+ modelo_skipgram.get_vector(pn)\n",
        "    except KeyError:\n",
        "      if pn.isnumeric():\n",
        "        pn = \"0\"*len(pn)\n",
        "        vetor_resultante =+ modelo_skipgram.get_vector(pn)\n",
        "      else:\n",
        "        vetor_resultante =+ modelo_skipgram.get_vector('unknown')\n",
        "  return vetor_resultante"
      ],
      "metadata": {
        "id": "X1kVbPzbOO-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matriz_vetores_skipgram(textos):\n",
        "  x = len(textos)\n",
        "  y = 300\n",
        "  matriz = np.zeros((x,y))\n",
        "\n",
        "  for i in range(x):\n",
        "    palavras_numeros = tokenizador(textos.iloc[i])\n",
        "    matriz[i] = combinacao_de_vetores_por_soma_skipgram(palavras_numeros)\n",
        "\n",
        "  return matriz"
      ],
      "metadata": {
        "id": "ZrkFAfYROJIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_vetores_treino_skipgram = matriz_vetores_skipgram(artigo_treino.title)\n",
        "matriz_vetores_teste_skipgram = matriz_vetores_skipgram(artigo_teste.title)"
      ],
      "metadata": {
        "id": "wcui7YzqOlQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_skipgram = LogisticRegression(max_iter = 200)\n",
        "LR_skipgram.fit(matriz_vetores_treino_skipgram, artigo_treino.category)\n",
        "label_previsao_skipgram = LR_skipgram.predict(matriz_vetores_teste_skipgram)\n",
        "CR_skipgram = classification_report(artigo_teste.category, label_previsao_skipgram)\n",
        "print(CR_skipgram)"
      ],
      "metadata": {
        "id": "OeovzLPkPG_t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
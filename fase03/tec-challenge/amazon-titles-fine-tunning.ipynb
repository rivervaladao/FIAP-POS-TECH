{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Instala\u00e7\u00e3o de depend\u00eancias\n", "!pip install transformers datasets scikit-learn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Importa\u00e7\u00e3o e Prepara\u00e7\u00e3o do Dataset\n", "import json\n", "import pandas as pd\n", "from sklearn.model_selection import train_test_split\n\n", "# Carregar o arquivo JSON\n", "from google.colab import files\n", "uploaded = files.upload()\n\n", "# Carregar o arquivo JSON\n", "with open(\"trn.json\", \"r\") as f:\n", "    data = json.load(f)\n\n", "# Transformar em DataFrame\n", "df = pd.DataFrame(data)\n\n", "# Manter apenas colunas relevantes\n", "df = df[[\"title\", \"content\"]].dropna()\n\n", "# Formatar os prompts para o fine-tuning\n", "df[\"prompt\"] = \"Pergunta: Descreva o produto | Contexto: \" + df[\"title\"]\n", "df[\"response\"] = df[\"content\"]\n\n", "# Dividir em treino e valida\u00e7\u00e3o\n", "train_data, val_data = train_test_split(df, test_size=0.1, random_state=42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Tokeniza\u00e7\u00e3o e Configura\u00e7\u00e3o do Modelo\n", "from transformers import AutoTokenizer, AutoModelForCausalLM\n\n", "# Escolher o modelo base\n", "model_name = \"gpt2\"  # Modelo base\n", "tokenizer = AutoTokenizer.from_pretrained(model_name)\n", "model = AutoModelForCausalLM.from_pretrained(model_name)\n\n", "# Tokenizar os dados\n", "def tokenize_function(example):\n", "    return tokenizer(\n", "        example[\"prompt\"],\n", "        text_target=example[\"response\"],\n", "        truncation=True,\n", "        padding=\"max_length\",\n", "        max_length=128\n", "    )\n\n", "# Tokenizar o conjunto de dados\n", "train_encodings = train_data.apply(lambda x: tokenize_function(x), axis=1)\n", "val_encodings = val_data.apply(lambda x: tokenize_function(x), axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Configura\u00e7\u00e3o e Execu\u00e7\u00e3o do Treinamento\n", "from transformers import Trainer, TrainingArguments\n\n", "# Configurar argumentos de treinamento\n", "training_args = TrainingArguments(\n", "    output_dir=\"./results\",\n", "    evaluation_strategy=\"epoch\",\n", "    learning_rate=2e-5,\n", "    per_device_train_batch_size=8,\n", "    num_train_epochs=3,\n", "    save_steps=10_000,\n", "    save_total_limit=2,\n", "    logging_dir='./logs',\n", "    logging_steps=500,\n", ")\n\n", "# Preparar o Trainer\n", "trainer = Trainer(\n", "    model=model,\n", "    args=training_args,\n", "    train_dataset=train_encodings,\n", "    eval_dataset=val_encodings,\n", ")\n\n", "# Fine-tuning\n", "trainer.train()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Avalia\u00e7\u00e3o e Gera\u00e7\u00e3o de Respostas\n", "def generate_response(question, title):\n", "    input_text = f\"Pergunta: {question} | Contexto: {title}\"\n", "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n", "    outputs = model.generate(inputs[\"input_ids\"], max_length=50)\n", "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n", "# Teste do modelo treinado\n", "question = \"Qual \u00e9 a descri\u00e7\u00e3o do produto?\"\n", "title = \"Laptop Dell Inspiron 15\"\n", "print(generate_response(question, title))"]}], "metadata": {"colab": {}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.16"}}, "nbformat": 4, "nbformat_minor": 0}
